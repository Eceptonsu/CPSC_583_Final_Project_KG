{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Setup: Install and imports"
      ],
      "metadata": {
        "id": "wSBpSzepZ-3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy\n",
        "!pip install ogb==1.2.4\n",
        "!pip install tqdm\n",
        "!pip install hyperopt\n",
        "!pip install ray==2.3.0\n",
        "!pip install torch\n",
        "\n",
        "!pip install deap\n",
        "!pip install -U tensorboardx"
      ],
      "metadata": {
        "id": "i4ZSactPZ96r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bb1767e-6e79-49bb-e756-a9dafff7c50c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Requirement already satisfied: ogb==1.2.4 in /usr/local/lib/python3.10/dist-packages (1.2.4)\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from ogb==1.2.4) (2.1.0+cu118)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from ogb==1.2.4) (1.23.5)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.10/dist-packages (from ogb==1.2.4) (4.66.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from ogb==1.2.4) (1.2.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb==1.2.4) (1.5.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from ogb==1.2.4) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb==1.2.4) (2.0.7)\n",
            "Requirement already satisfied: outdated>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ogb==1.2.4) (0.2.2)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb==1.2.4) (67.7.2)\n",
            "Requirement already satisfied: littleutils in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb==1.2.4) (0.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb==1.2.4) (2.31.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb==1.2.4) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb==1.2.4) (2023.3.post1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb==1.2.4) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb==1.2.4) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb==1.2.4) (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->ogb==1.2.4) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->ogb==1.2.4) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->ogb==1.2.4) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->ogb==1.2.4) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->ogb==1.2.4) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->ogb==1.2.4) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->ogb==1.2.4) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.2.0->ogb==1.2.4) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb==1.2.4) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb==1.2.4) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb==1.2.4) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.2.0->ogb==1.2.4) (1.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.10/dist-packages (0.2.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.11.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.16.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from hyperopt) (3.2.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt) (0.18.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from hyperopt) (4.66.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt) (2.2.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt) (0.10.9.7)\n",
            "Requirement already satisfied: ray==2.3.0 in /usr/local/lib/python3.10/dist-packages (2.3.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from ray==2.3.0) (23.1.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray==2.3.0) (8.1.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray==2.3.0) (3.13.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray==2.3.0) (4.19.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray==2.3.0) (1.0.7)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray==2.3.0) (3.20.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray==2.3.0) (6.0.1)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray==2.3.0) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray==2.3.0) (1.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray==2.3.0) (2.31.0)\n",
            "Requirement already satisfied: virtualenv>=20.0.24 in /usr/local/lib/python3.10/dist-packages (from ray==2.3.0) (20.25.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ray==2.3.0) (23.2)\n",
            "Requirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.10/dist-packages (from ray==2.3.0) (1.59.3)\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from ray==2.3.0) (1.23.5)\n",
            "Requirement already satisfied: distlib<1,>=0.3.7 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.0.24->ray==2.3.0) (0.3.8)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.0.24->ray==2.3.0) (4.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray==2.3.0) (2023.11.2)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray==2.3.0) (0.31.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray==2.3.0) (0.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ray==2.3.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray==2.3.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray==2.3.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray==2.3.0) (2023.11.17)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: deap in /usr/local/lib/python3.10/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deap) (1.23.5)\n",
            "Requirement already satisfied: tensorboardx in /usr/local/lib/python3.10/dist-packages (2.6.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardx) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardx) (23.2)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardx) (3.20.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zse_Hb3TKFl8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e25fc9d-f3fc-4f14-cecc-212c33410835"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:The OGB package is out of date. Your version is 1.2.4, while the latest version is 1.3.6.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from hyperopt import hp\n",
        "from hyperopt import tpe\n",
        "from ray import tune\n",
        "from ray.tune.search.hyperopt import HyperOptSearch\n",
        "from ray.air.config import RunConfig\n",
        "from ogb.linkproppred import LinkPropPredDataset, Evaluator\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "from deap import base, creator, tools, algorithms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jzzQWSg7HIG",
        "outputId": "861b7599-09af-4466-9ec4-70743581e3cb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset preparation:\n",
        "\n",
        "Load the rank file for different datasets:\n",
        "1.   obgl-biokg (KGBench, ComplexRP, TripleRE)\n",
        "2.   ogbl-wikikg2 (Text, InterHTPlus, StarGraph)\n",
        "\n"
      ],
      "metadata": {
        "id": "YC2neaD7aJea"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hBTYXuhbKFmC"
      },
      "outputs": [],
      "source": [
        "dataset_name = 'ogbl-biokg' # ogbl-biokg, ogbl-wikikg2\n",
        "\n",
        "rank_path = f\"./gdrive/MyDrive/CPSC_583_Dataset/{dataset_name}\"\n",
        "checkpoint_path = f\"weights/{dataset_name}_rel_weights.npy\"\n",
        "\n",
        "max_concurrent_trials = 8\n",
        "num_samples = 100\n",
        "num_initial_points = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "UMTfTom9KFmC"
      },
      "outputs": [],
      "source": [
        "evaluator = Evaluator(name=dataset_name)\n",
        "\n",
        "if dataset_name == 'ogbl-biokg':\n",
        "    model_names = ['rescal', 'rotate', 'cp', 'complex', 'unibi_3', 'triplere'] #, 'transe', 'tucker']\n",
        "else:\n",
        "    raise NotImplementedError(f\"Unsupported dataset: {dataset_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "SLi83-pwKFmD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da5f06a2-6793-4e77-ba6a-bba7a406ac5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset: ogbl-biokg\n",
            "(162870, 1002)\n"
          ]
        }
      ],
      "source": [
        "print(f\"Loading dataset: {dataset_name}\")\n",
        "ranks = {\n",
        "    'valid': [np.load(f\"{rank_path}/{m}_valid_ranks.npy\") for m in model_names],\n",
        "    'test': [np.load(f\"{rank_path}/{m}_test_ranks.npy\") for m in model_names]\n",
        "}\n",
        "print(ranks['test'][0].shape)\n",
        "\n",
        "n_model = len(ranks['test'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "QokW6XpbKFmF"
      },
      "outputs": [],
      "source": [
        "dataset = LinkPropPredDataset(name=dataset_name)\n",
        "split_edge = dataset.get_edge_split()\n",
        "train_triples, valid_triples, test_triples = split_edge[\"train\"], split_edge[\"valid\"], split_edge[\"test\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "fxon3LrkKFmG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daaa0815-997b-4189-9715-b61d1447f0ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "51\n"
          ]
        }
      ],
      "source": [
        "if dataset_name == 'ogbl-biokg':\n",
        "    test_relation = test_triples['relation']\n",
        "    valid_relation = valid_triples['relation']\n",
        "    num_relation = int(max(train_triples['relation']))+1\n",
        "elif dataset_name == 'ogbl-wikikg2':\n",
        "    origin_num_relation = int(max(train_triples['relation'].max(), valid_triples['relation'].max(), test_triples['relation'].max()))+1\n",
        "    test_relation = np.concatenate((test_triples['relation'], test_triples['relation'] + origin_num_relation), axis=0)\n",
        "    valid_relation = np.concatenate((valid_triples['relation'], valid_triples['relation'] + origin_num_relation), axis=0)\n",
        "    num_relation = int(max(test_relation.max(), valid_relation.max())) + 1\n",
        "\n",
        "print(num_relation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "LB5Y6pF7KFmG"
      },
      "outputs": [],
      "source": [
        "rel_indexes = {\n",
        "    'valid': {},\n",
        "    'test': {}\n",
        "} # relation_id -> np array\n",
        "\n",
        "for relation_id in range(num_relation):\n",
        "    rel_indexes['test'][relation_id] = np.where(test_relation == relation_id)[0]\n",
        "    rel_indexes['valid'][relation_id] = np.where(valid_relation == relation_id)[0]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utility functions"
      ],
      "metadata": {
        "id": "-b1nZp3weaVS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "_X5GB9PKKFmE"
      },
      "outputs": [],
      "source": [
        "def eval_model(sub_ranks):\n",
        "    new_ranks = 502 - sub_ranks\n",
        "\n",
        "    mrr_head = evaluator.eval({'y_pred_pos': new_ranks[:, 0], 'y_pred_neg': new_ranks[:, 1:501]})['mrr_list'].mean()\n",
        "    mrr_tail = evaluator.eval({'y_pred_pos': new_ranks[:, 501], 'y_pred_neg': new_ranks[:, 502:]})['mrr_list'].mean()\n",
        "\n",
        "    return {'mrr': (mrr_head + mrr_tail) / 2}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Modification\n",
        "def adjust_weights_simple(current_weights, performance_metrics, adjustment_factor=0.1):\n",
        "    \"\"\"\n",
        "    Adjust the ensemble weights based on performance metrics.\n",
        "    Here, a simple strategy is used: increase the weight of better-performing models\n",
        "    by a factor and decrease the weight of others. This is a basic example and\n",
        "    can be replaced with more sophisticated methods.\n",
        "    \"\"\"\n",
        "    best_model_index = np.argmax(performance_metrics)\n",
        "    for i in range(len(current_weights)):\n",
        "        if i == best_model_index:\n",
        "            current_weights[i] += adjustment_factor\n",
        "        else:\n",
        "            current_weights[i] -= adjustment_factor / (len(current_weights) - 1)\n",
        "    # Ensure weights remain normalized\n",
        "    current_weights = np.maximum(current_weights, 0)\n",
        "    current_weights /= np.sum(current_weights)\n",
        "    return current_weights\n",
        "\n",
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum(axis=0)\n",
        "\n",
        "def adjust_weights(current_weights, gradient, learning_rate=0.01, momentum=0.9):\n",
        "    \"\"\"\n",
        "    Adjust weights using a gradient-based approach with a learning rate and momentum.\n",
        "    \"\"\"\n",
        "    gradient = np.array(gradient)\n",
        "    previous_update = np.array(adjust_weights.previous_update)\n",
        "\n",
        "    update = momentum * previous_update - learning_rate * gradient\n",
        "    new_weights = current_weights + update\n",
        "    # Normalize with softmax\n",
        "    new_weights = softmax(new_weights)\n",
        "    adjust_weights.previous_update = update\n",
        "    return new_weights"
      ],
      "metadata": {
        "id": "r-w8754cHGq-"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "p2CkiPxAKFmH"
      },
      "outputs": [],
      "source": [
        "def objective(config, data, dynamic=False, current_weights=None):\n",
        "    sub_ranks = data\n",
        "    weights = np.array([config[f\"w_{i}\"] for i in range(len(sub_ranks))])\n",
        "    ranks_avg = np.average(sub_ranks, weights=weights, axis=0)\n",
        "    mrr = eval_model(ranks_avg)\n",
        "\n",
        "    if not dynamic:\n",
        "        return mrr\n",
        "\n",
        "    gradient = np.array([mrr['mrr'] for _ in range(len(sub_ranks))])\n",
        "    new_weights = adjust_weights(current_weights, gradient, learning_rate, momentum)\n",
        "    return mrr, new_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Machine learning ensemble\n",
        "\n",
        "1. Default Configuration Setup\n",
        "2. Loading or Initializing Ensemble Weights\n",
        "3. Defining the Search Space for Hyperparameter Optimization:\n",
        "4. Setting Up and Running the Optimization Process:\n",
        "5. Potential Saving of Computed Weights:\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lpujuvV1iQJi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "WcBr2O2qKFmI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "e804db56-8118-4eb2-cfc6-1a3d104aefca"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=478376)\u001b[0m WARNING:root:The OGB package is out of date. Your version is 1.2.4, while the latest version is 1.3.6.\n",
            "\u001b[2m\u001b[36m(pid=478390)\u001b[0m WARNING:root:The OGB package is out of date. Your version is 1.2.4, while the latest version is 1.3.6.\n",
            "\u001b[2m\u001b[36m(pid=478453)\u001b[0m WARNING:root:The OGB package is out of date. Your version is 1.2.4, while the latest version is 1.3.6.\n",
            "\u001b[2m\u001b[36m(pid=478490)\u001b[0m WARNING:root:The OGB package is out of date. Your version is 1.2.4, while the latest version is 1.3.6.\n",
            "\u001b[2m\u001b[36m(pid=478512)\u001b[0m WARNING:root:The OGB package is out of date. Your version is 1.2.4, while the latest version is 1.3.6.\n",
            "\u001b[2m\u001b[36m(pid=478618)\u001b[0m WARNING:root:The OGB package is out of date. Your version is 1.2.4, while the latest version is 1.3.6.\n",
            "\u001b[2m\u001b[36m(pid=478581)\u001b[0m WARNING:root:The OGB package is out of date. Your version is 1.2.4, while the latest version is 1.3.6.\n",
            "\u001b[2m\u001b[36m(pid=478709)\u001b[0m WARNING:root:The OGB package is out of date. Your version is 1.2.4, while the latest version is 1.3.6.\n",
            "2023-12-13 04:59:50,148\tWARNING util.py:244 -- The `callbacks.on_trial_result` operation took 0.581 s, which may be a performance bottleneck.\n",
            "2023-12-13 04:59:50,151\tWARNING util.py:244 -- The `process_trial_result` operation took 0.589 s, which may be a performance bottleneck.\n",
            "2023-12-13 04:59:50,153\tWARNING util.py:244 -- Processing trial results took 0.591 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
            "2023-12-13 04:59:50,154\tWARNING util.py:244 -- The `process_trial_result` operation took 0.592 s, which may be a performance bottleneck.\n",
            "2023-12-13 04:59:53,272\tWARNING util.py:244 -- The `reset` operation took 0.617 s, which may be a performance bottleneck.\n",
            "2023-12-13 04:59:53,279\tWARNING util.py:244 -- The `start_trial` operation took 0.625 s, which may be a performance bottleneck.\n",
            "2023-12-13 05:00:15,742\tWARNING util.py:244 -- The `reset` operation took 0.584 s, which may be a performance bottleneck.\n",
            "2023-12-13 05:00:15,750\tWARNING util.py:244 -- The `start_trial` operation took 0.594 s, which may be a performance bottleneck.\n",
            "100%|██████████| 51/51 [34:10<00:00, 40.20s/it]\n"
          ]
        }
      ],
      "source": [
        "momentum = 0.9\n",
        "learning_rate = 0.01\n",
        "dynamic_weight_adjust = True\n",
        "dynamic_iterations = 16 if dynamic_weight_adjust else 1\n",
        "\n",
        "default_config = {\n",
        "    'w_0': 0.16,\n",
        "    'w_1': 0.16,\n",
        "    'w_2': 0.16,\n",
        "    'w_3': 0.17,\n",
        "    'w_4': 0.17,\n",
        "    'w_5': 0.17,\n",
        "}\n",
        "\n",
        "initial_weights = np.array([default_config['w_0'], default_config['w_1'], default_config['w_2'], default_config['w_3'], default_config['w_4'], default_config['w_5']])\n",
        "adjust_weights.previous_update = np.zeros(len(initial_weights))\n",
        "\n",
        "if checkpoint_path and os.path.exists(checkpoint_path):\n",
        "    print(\"Load existing models\")\n",
        "    rel_weights = np.load(checkpoint_path)\n",
        "else:\n",
        "    print(\"Searching for ensemble weights\")\n",
        "    rel_weights = np.zeros((num_relation, n_model))\n",
        "\n",
        "    search_space = {f\"w_{i}\": hp.uniform(f\"w_{i}\", 0, 1)  for i in range(n_model)}\n",
        "    hyperopt_search = HyperOptSearch(search_space, metric=\"mrr\", mode=\"max\", n_initial_points=num_initial_points)\n",
        "\n",
        "    for rel_id in tqdm(range(num_relation)):\n",
        "        if len(rel_indexes['valid'][rel_id]) == 0:\n",
        "            # default weights\n",
        "            rel_weights[rel_id] = np.fromiter(default_config.values(), dtype=np.float32)\n",
        "            continue\n",
        "\n",
        "        subranks = [model_rank[rel_indexes['valid'][rel_id]] for model_rank in ranks['valid']]\n",
        "        tuner = tune.Tuner(tune.with_parameters(objective, data=(subranks)), param_space=search_space,\n",
        "                tune_config=tune.TuneConfig(num_samples=num_samples, search_alg=hyperopt_search, max_concurrent_trials=max_concurrent_trials),\n",
        "                run_config=RunConfig(verbose=0))\n",
        "        results = tuner.fit()\n",
        "\n",
        "        best_weights = np.fromiter(results.get_best_result(metric=\"mrr\", mode=\"max\").config.values(), dtype='float32')\n",
        "\n",
        "        if dynamic_weight_adjust:\n",
        "            # Dynamic weight adjustment\n",
        "            current_weights = best_weights\n",
        "            for _ in range(dynamic_iterations):\n",
        "                mrr, current_weights = objective({'w_0': current_weights[0], 'w_1': current_weights[1], 'w_2': current_weights[2], 'w_3': current_weights[3], 'w_4': current_weights[4], 'w_5': current_weights[5]}, subranks, dynamic_weight_adjust, current_weights=current_weights)\n",
        "\n",
        "            rel_weights[rel_id] = current_weights\n",
        "        else:\n",
        "            rel_weights[rel_id] = best_weights\n",
        "\n",
        "    # np.save(f\"rel_weights.npy\", rel_weights)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "w-CAbWbPKFmJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e854ab20-d6e2-4b89-a07c-aeeddc258fa8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating\n",
            " 100%|██████████| 51/51 [00:30<00:00,  1.66it/s]\n",
            " Test MRR: 0.7873165219712932\n",
            " Validation MRR: 0.3981841449958312\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Evaluating\")\n",
        "rel_res = {\n",
        "    'test': [{'mrr': 0} for _ in range(num_relation)],\n",
        "    'valid': [{'mrr': 0} for _ in range(num_relation)]\n",
        "}\n",
        "\n",
        "for rel_id in tqdm(range(num_relation)):\n",
        "    # test results\n",
        "    if len(rel_indexes['test'][rel_id]) == 0:\n",
        "        continue\n",
        "    sub_ranks = [model_rank[rel_indexes['test'][rel_id]] for model_rank in ranks['test']]\n",
        "    config = {f\"w_{i}\": rel_weights[rel_id][i] for i in range(n_model)}\n",
        "    metrics = objective(config, (sub_ranks))\n",
        "    rel_res['test'][rel_id] = metrics\n",
        "\n",
        "    # valid results\n",
        "    if len(rel_indexes['valid'][rel_id]) == 0:\n",
        "        continue\n",
        "    sub_ranks = [model_rank[rel_indexes['valid'][rel_id]] for model_rank in ranks['valid']]\n",
        "    config = {f\"w_{i}\": rel_weights[rel_id][i] for i in range(n_model)}\n",
        "    metrics = objective(config, (sub_ranks))\n",
        "    rel_res['valid'][rel_id] = metrics\n",
        "\n",
        "test_mrr = 0\n",
        "valid_mrr = 0\n",
        "\n",
        "for rel_id in range(num_relation):\n",
        "    test_mrr += rel_res['test'][rel_id]['mrr'] * len(rel_indexes['test'][rel_id])\n",
        "    valid_mrr += rel_res['valid'][rel_id]['mrr'] * len(rel_indexes['valid'][rel_id])\n",
        "\n",
        "test_mrr = test_mrr / ranks['test'][0].shape[0]\n",
        "valid_mrr = valid_mrr / ranks['valid'][0].shape[0]\n",
        "\n",
        "print(f\"\\nTest MRR: {test_mrr}\\nValidation MRR: {valid_mrr}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Genetic Algorithm"
      ],
      "metadata": {
        "id": "tfgpqIfhOQwl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the fitness function\n",
        "def evalModel(individual):\n",
        "    weights = np.array(individual)\n",
        "    normalized_weights = weights / np.sum(weights)\n",
        "\n",
        "    # Compute the weighted average ranks across all relations\n",
        "    all_mrrs = []\n",
        "    for rel_id in range(num_relation):\n",
        "        if len(rel_indexes['valid'][rel_id]) > 0:\n",
        "            sub_ranks = [model_rank[rel_indexes['valid'][rel_id]] for model_rank in ranks['valid']]\n",
        "            ranks_avg = np.average(sub_ranks, weights=normalized_weights, axis=0)\n",
        "            mrr = eval_model(ranks_avg)\n",
        "            all_mrrs.append(mrr['mrr'])\n",
        "\n",
        "    # Average MRR across all relations\n",
        "    avg_mrr = np.mean(all_mrrs) if all_mrrs else 0\n",
        "\n",
        "    return avg_mrr,\n",
        "\n",
        "# Set up the GA\n",
        "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
        "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
        "\n",
        "toolbox = base.Toolbox()\n",
        "toolbox.register(\"attr_float\", np.random.uniform, 0, 1)\n",
        "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_float, n=n_model)\n",
        "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "\n",
        "toolbox.register(\"evaluate\", evalModel)\n",
        "toolbox.register(\"mate\", tools.cxBlend, alpha=0.5)\n",
        "toolbox.register(\"mutate\", tools.mutGaussian, mu=0, sigma=1, indpb=0.2)\n",
        "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
        "\n",
        "# GA parameters\n",
        "population_size = 50\n",
        "number_of_generations = 50\n",
        "\n",
        "# Initialize population\n",
        "population = toolbox.population(n=population_size)\n",
        "\n",
        "# Run the GA\n",
        "for gen in range(number_of_generations):\n",
        "    offspring = algorithms.varAnd(population, toolbox, cxpb=0.5, mutpb=0.2)\n",
        "    fits = toolbox.map(toolbox.evaluate, offspring)\n",
        "    for fit, ind in zip(fits, offspring):\n",
        "        ind.fitness.values = fit\n",
        "    population = toolbox.select(offspring, k=len(population))\n",
        "    best_ind = tools.selBest(population, k=1)[0]\n",
        "    #print(f\"Generation {gen}: Best MRR: {best_ind.fitness.values[0]}\")\n",
        "\n",
        "top_individual = tools.selBest(population, k=1)[0]\n",
        "print(f\"Best MRR: {top_individual.fitness.values[0]}\")"
      ],
      "metadata": {
        "id": "TeDapFs0TGrZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7d7a70c-f9ac-47b5-e08b-47b949e262ab"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best MRR: 0.652365818047056\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "c5f194073aaff85b697eed6685e89bdb344177f148991fb6fdbaca70a347ec53"
      }
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}